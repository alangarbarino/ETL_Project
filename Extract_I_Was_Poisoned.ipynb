{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Data from iwaspoisoned.com website using web scraping.\n",
    "# Then populate the information in a MongoDB\n",
    "# (to facilitate teaming, export the MongoDB to a JSON file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from pprint import pprint\n",
    "\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pymongo\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize PyMongo to work with MongoDBs\n",
    "conn = 'mongodb://localhost:27017'\n",
    "client = pymongo.MongoClient(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define database and collection\n",
    "db = client.etl_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the splinter Browser\n",
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION: get_incident_detail()\n",
    "# This function accepts a url that points to a single incident detail page\n",
    "# and returns a dictionary with info from that page.\n",
    "#\n",
    "# Note: This function performs special parsing of addresses in the United States.\n",
    "# Addresses in the US will be parsed down to individual components\n",
    "# (street, street2, street3, city, state, zipcode, country)\n",
    "# In addition, these parsed components are then recombined\n",
    "# to form the full address in \"standard\" format\n",
    "# (i.e., Zipcode after the state instead of before state)\n",
    "#\n",
    "# Addresses for other countries are provided only as an address string\n",
    "#\n",
    "# Arguments:\n",
    "#    incident_detail_url: URL of the incident detail page\n",
    "#\n",
    "# Returns:\n",
    "#    retval: A dictionary containing the incident detail page info\n",
    "\n",
    "def get_incident_detail(a_url):\n",
    "\n",
    "    # URL of page to be scraped\n",
    "    # url_incident = 'https://iwaspoisoned.com/incident/chick-fil-a-north-fairfield-road-beavercreek-oh-usa-168576#emailscroll'\n",
    "    # url_incident = 'https://iwaspoisoned.com/incident/subway-terminal-3-silver-dart-drive-toronto-on-canada-168642#emailscroll'\n",
    "    if len(a_url) == 0:\n",
    "        return None\n",
    "    \n",
    "    url_incident = a_url\n",
    "    \n",
    "    # Retrieve page with the requests module\n",
    "    response = requests.get(url_incident)\n",
    "\n",
    "    # Create BeautifulSoup object; parse with 'lxml'\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "\n",
    "    # Examine the results, then determine element that contains sought info\n",
    "    # results are returned as an iterable list\n",
    "    results = soup.find_all('div', class_='single-incident')\n",
    "\n",
    "    for r in results:\n",
    "        # Incident detail page - title\n",
    "        # incident_detail_title = r.find('h1', class_='h1 post-title').text.strip()\n",
    "\n",
    "        # Address\n",
    "        try:\n",
    "            addr_info = r.find('span', class_='pl-1 py-0 text-muted').text.strip()\n",
    "            incident_address = ' '.join(addr_info.split())\n",
    "            \n",
    "        except AttributeError:\n",
    "            addr_info = \"\"\n",
    "            incident_address = \"\"\n",
    "\n",
    "        # Ok, we now have an address of the form:\n",
    "        # 2360 North Fairfield Road, Beavercreek, 45431 Ohio, United States\n",
    "        # But, would be nice to be able to break this up into\n",
    "        # individual components to facilitate address matching,\n",
    "        # Especially with the non-standard location of the zipcode\n",
    "\n",
    "        if \"United States\" in incident_address:\n",
    "            # Create a list of address items\n",
    "            ai_list = incident_address.split(',')\n",
    "\n",
    "            # Some items are mandatory and are at the end of the list of length = N\n",
    "            # N-1: Country e.g. \"United States\"\n",
    "            # N-2: Zipcode and State e.g. \"45431 Ohio\"\n",
    "            # N-3: City\n",
    "            # Other entries 0 to N-4: Street/Apt/etc.\n",
    "\n",
    "            ai_size = len( ai_list )\n",
    "            # Country\n",
    "            incident_address_country = ai_list[ai_size-1].strip()\n",
    "\n",
    "            # Split the next entry to get state and zipcode\n",
    "            zs_info = ai_list[ai_size-2].strip()\n",
    "            zs_delim = zs_info.find(' ')\n",
    "            # print(f\"zs_delim: {zs_delim}, zs_info: {zs_info}\")\n",
    "            incident_address_zipcode = zs_info[:zs_delim].strip()\n",
    "            incident_address_state = zs_info[zs_delim:].strip()\n",
    "\n",
    "            # City\n",
    "            incident_address_city = ai_list[ai_size-3].strip()\n",
    "\n",
    "            # Process up to 3 \"street\" type entries\n",
    "            incident_address_street = \"\"\n",
    "            incident_address_street2 = \"\"\n",
    "            incident_address_street3 = \"\"\n",
    "\n",
    "            # print(f\"ai_size: {ai_size}\")\n",
    "            # First street address item\n",
    "            if ai_size >= 4:\n",
    "                incident_address_street = ai_list[0].strip()\n",
    "\n",
    "            # Second street address item\n",
    "            if ai_size >= 5:\n",
    "                incident_address_street2 = ai_list[1].strip()\n",
    "\n",
    "            # Third street address item\n",
    "            if ai_size >= 6:\n",
    "                incident_address_street3 = ai_list[i].strip()\n",
    "\n",
    "            # Reform the address - with standard formating\n",
    "            incident_address_standard = incident_address_street\n",
    "            if len(incident_address_street2) > 0:\n",
    "                incident_address_standard += \", \" + incident_address_street2\n",
    "            if len(incident_address_street3) > 0:\n",
    "                incident_address_standard += \", \" + incident_address_street3\n",
    "            if len(incident_address_city) > 0:\n",
    "                incident_address_standard += \", \" + incident_address_city\n",
    "            if len(incident_address_state) > 0:\n",
    "                incident_address_standard += \", \" + incident_address_state\n",
    "            if len(incident_address_zipcode) > 0:\n",
    "                incident_address_standard += \" \" + incident_address_zipcode\n",
    "            if len(incident_address_country) > 0:\n",
    "                incident_address_standard += \", \" + incident_address_country\n",
    "\n",
    "\n",
    "            #print(f\">>> Incident Detail - Address: {incident_address}\")\n",
    "            #print(f\">>> Incident Detail - Address - Standard: {incident_address_standard}\")\n",
    "            #print(f\">>> Incident Detail - Address - Street: {incident_address_street}\")\n",
    "            #print(f\">>> Incident Detail - Address - Street2: {incident_address_street2}\")\n",
    "            #print(f\">>> Incident Detail - Address - Street3: {incident_address_street3}\")\n",
    "            #print(f\">>> Incident Detail - Address - City: {incident_address_city}\")\n",
    "            #print(f\">>> Incident Detail - Address - State: {incident_address_state}\")\n",
    "            #print(f\">>> Incident Detail - Address - Zipcode: {incident_address_zipcode}\")\n",
    "            #print(f\">>> Incident Detail - Address - Country: {incident_address_country}\")\n",
    "            #print(\"-\"*40)\n",
    "\n",
    "            # Place all this good info into a dictionary\n",
    "            detail_post_item = {\n",
    "                'incident_address': incident_address,\n",
    "                'incident_address_standard': incident_address_standard,\n",
    "                'incident_address_street': incident_address_street,\n",
    "                'incident_address_street2': incident_address_street2,\n",
    "                'incident_address_street3': incident_address_street3,\n",
    "                'incident_address_city': incident_address_city,\n",
    "                'incident_address_state': incident_address_state,\n",
    "                'incident_address_zipcode': incident_address_zipcode,\n",
    "                'incident_address_country': incident_address_country\n",
    "            }\n",
    "\n",
    "        else:\n",
    "            # Ok, for other countries, don't try to parse the incident_address\n",
    "            # print(f\">>> Incident Detail - Address: {incident_address}\")\n",
    "            # print(\"-\"*40)\n",
    "\n",
    "            # Place all this good info into a dictionary\n",
    "            detail_post_item = {\n",
    "                'incident_address': incident_address,\n",
    "            }\n",
    "\n",
    "        # pprint(detail_post_item)\n",
    "        \n",
    "        return detail_post_item\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION: parse_one_incident()\n",
    "# This function accepts a Beautiful Soup object that contains a single incident\n",
    "# and returns a dictionary with info for that incident.\n",
    "# This includes a call to the get_incident_detail() function,\n",
    "# which gets needed information from the detail page for this incident\n",
    "#\n",
    "# Arguments:\n",
    "#    a_bsobj: A Beautiful Soup object containing a single incident\n",
    "#\n",
    "# Returns:\n",
    "#    retval: A dictionary containing the incident detail page info\n",
    "\n",
    "def parse_one_incident(a_bsobj):\n",
    "    \n",
    "    # Create BeautifulSoup object; parse with 'lxml'\n",
    "    r = a_bsobj\n",
    "\n",
    "    # Get the primary incident report info from the main box\n",
    "    main_box = r.find('div', class_='report-first-box')\n",
    "    \n",
    "    # Date the incident occurred\n",
    "    try:\n",
    "        incident_date = main_box.find('p', class_ = 'report-date').text.strip()\n",
    "        \n",
    "    except AttributeError:\n",
    "        incident_date = \"\"\n",
    "        \n",
    "\n",
    "    # Title of the incident\n",
    "    try:\n",
    "        incident_title = main_box.find('a')['title']\n",
    "\n",
    "    except AttributeError:\n",
    "        incident_title = \"\"\n",
    "    \n",
    "    # Remove the tag phrase from the title if it's present\n",
    "    if \"- Got Food Poisoning? Report it now\" in incident_title:\n",
    "        i_delim = incident_title.find(\"- Got Food Poisoning? Report it now\")\n",
    "        incident_title = incident_title[:i_delim].strip()\n",
    "\n",
    "    # URL of the per-incident details\n",
    "    try:\n",
    "        incident_url = main_box.find('a')['href'].strip()\n",
    "\n",
    "    except AttributeError:\n",
    "        incident_url = \"\"\n",
    "\n",
    "    # Get the Symptoms\n",
    "    report_tags = main_box.find_all('p', class_ = 'report-tag')\n",
    "\n",
    "    # Parse each report tag into its proper field\n",
    "    incident_symptoms = \"\"\n",
    "    incident_report_type = \"\"\n",
    "    incident_misc = \"\"\n",
    "\n",
    "    for rt in report_tags:\n",
    "        # Get the text in this tag\n",
    "        rt_info = rt.text.strip()\n",
    "\n",
    "        # Symptoms\n",
    "        if \"Symptoms:\" in rt_info:\n",
    "            incident_symptoms = [ s.replace(',','') for s in rt_info[len(\"Symptoms: \"):].split() ]\n",
    "\n",
    "        # Report Type\n",
    "        elif \"Report Type:\" in rt_info:\n",
    "            incident_report_type = rt_info[len(\"Report Type: \"):]\n",
    "\n",
    "        # Ok... no idea what this report tag contains\n",
    "        else:\n",
    "            incident_misc = rt_info\n",
    "\n",
    "    #pprint(main_box)\n",
    "    #print(f\">>> Incident Date: {incident_date}\")\n",
    "    #print(f\">>> Incident Title: {incident_title}\")\n",
    "    #print(f\">>> Incident URL: {incident_url}\")\n",
    "    #print(f\">>> Incident Report Type: {incident_report_type}\")\n",
    "    #print(f\">>> Incident Symptoms: {incident_symptoms}\")\n",
    "    #print(f\">>> Incident Misc Info: {incident_misc}\")\n",
    "    #print(\"-\"*40)\n",
    "\n",
    "    # Get the full description of the incident\n",
    "    # Assume this couple be populated in multiple paragraphs\n",
    "    desc_box = r.find('div', class_='report-second-box')\n",
    "    desc_list = desc_box.find_all('p')\n",
    "    incident_description = \"\"\n",
    "    for d in desc_list:\n",
    "        incident_description += d.text.strip()\n",
    "\n",
    "    #pprint(descbox)\n",
    "    #print(f\">>> Description: {incident_description}\")\n",
    "    #print(\"-\"*40)\n",
    "\n",
    "    # Go to the detail page to get the one piece of info we\n",
    "    # need that's not on the main page - the address!\n",
    "    incident_address_info = get_incident_detail(incident_url)\n",
    "\n",
    "    # Place all this good info into a dictionary\n",
    "    post_item = {\n",
    "        'incident_title': incident_title,\n",
    "        'incident_date': incident_date,\n",
    "        'incident_url': incident_url,\n",
    "        'incident_report_type': incident_report_type,\n",
    "        'incident_symptoms': incident_symptoms,\n",
    "        'incident_misc': incident_misc,\n",
    "        'incident_address_info': incident_address_info,\n",
    "        'incident_description': incident_description\n",
    "    }\n",
    "    #pprint(post_item)\n",
    "\n",
    "    return post_item\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# FUNCTION: parse_incident_page()\n",
    "# This function accepts an HTML string from an\n",
    "# IWP website page that contains multiple incidents.\n",
    "# It then loops through the incidents on the page and the uses parse_one_incident()\n",
    "# function to grab the relevant incident info from the page.\n",
    "#\n",
    "# NOTE: The incidents are filtered to keep only those that occurred in the USA\n",
    "# since our project is focused on Chicago, IL.\n",
    "#\n",
    "# Arguments:\n",
    "#    a_html: A string of HTML content containing multiple incidents\n",
    "#\n",
    "# Returns:\n",
    "#    retval: A list of dictionaries of USA incident information\n",
    "\n",
    "def parse_incident_page(a_html):\n",
    "    \n",
    "    # Do a basic check\n",
    "    if len(a_html) == 0:\n",
    "        return None\n",
    "\n",
    "    # Create BeautifulSoup object; parse with 'lxml'\n",
    "    soup = BeautifulSoup(a_html, 'lxml')\n",
    "\n",
    "    # Examine the results, then determine element that contains sought info\n",
    "    # results are returned as an iterable list\n",
    "    results = soup.find_all('div', class_='row div-report-box')\n",
    "\n",
    "    # Keep track of how many entries we've added\n",
    "    n_incidents = 0\n",
    "\n",
    "    # Get info for all of the incidents on this page\n",
    "    incident_list = []\n",
    "    try:\n",
    "        for r in results:\n",
    "\n",
    "            # Parse this incident\n",
    "            incident_info = parse_one_incident(r)\n",
    "            #pprint(incident_info)\n",
    "\n",
    "            # Only retain incidents in the United States\n",
    "            # (Our scope is City of Chicago, so keeping all of USA should be sufficient)\n",
    "            if \"United States\" in incident_info['incident_address_info']['incident_address']:\n",
    "                # Append this USA incident to the list\n",
    "                incident_list.append( incident_info )\n",
    "                n_incidents += 1\n",
    "\n",
    "                # Print a progress message\n",
    "                # print(f\">> Added incident #{n_incidents}: {incident_info['incident_title']}\")\n",
    "\n",
    "            #DEBUG ****************************************\n",
    "            #if n_incidents > 3:\n",
    "            #    break\n",
    "\n",
    "    except TypeError:\n",
    "        # If an iterable is not provided in \"results\", then fail gracefully\n",
    "        pass\n",
    "            \n",
    "            \n",
    "    # Return the list of dictionaries with USA incident info\n",
    "    return incident_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1: 7 of 7 incidents added to DB. Total incidents: 176\n",
      "Page 2: 8 of 8 incidents added to DB. Total incidents: 184\n",
      "Page 3: 9 of 9 incidents added to DB. Total incidents: 193\n",
      "Page 4: 9 of 9 incidents added to DB. Total incidents: 202\n",
      "Page 5: 9 of 9 incidents added to DB. Total incidents: 211\n",
      "Page 6: 10 of 10 incidents added to DB. Total incidents: 221\n",
      "Page 7: 10 of 10 incidents added to DB. Total incidents: 231\n",
      "Page 8: 7 of 7 incidents added to DB. Total incidents: 238\n",
      "Page 9: 9 of 9 incidents added to DB. Total incidents: 247\n",
      "Page 10: 9 of 9 incidents added to DB. Total incidents: 256\n",
      "Page 11: 8 of 8 incidents added to DB. Total incidents: 264\n",
      "Page 12: 8 of 8 incidents added to DB. Total incidents: 272\n",
      "Page 13: 8 of 8 incidents added to DB. Total incidents: 280\n",
      "Page 14: 8 of 8 incidents added to DB. Total incidents: 288\n",
      "Page 15: 8 of 8 incidents added to DB. Total incidents: 296\n",
      "Page 16: 9 of 9 incidents added to DB. Total incidents: 305\n",
      "Page 17: 8 of 8 incidents added to DB. Total incidents: 313\n",
      "Page 18: 10 of 10 incidents added to DB. Total incidents: 323\n",
      "Page 19: 9 of 9 incidents added to DB. Total incidents: 332\n",
      "Page 20: 7 of 7 incidents added to DB. Total incidents: 339\n",
      "Page 21: 8 of 8 incidents added to DB. Total incidents: 347\n",
      "Page 22: 7 of 7 incidents added to DB. Total incidents: 354\n",
      "Page 23: 9 of 9 incidents added to DB. Total incidents: 363\n",
      "Page 24: 9 of 9 incidents added to DB. Total incidents: 372\n",
      "Page 25: 9 of 9 incidents added to DB. Total incidents: 381\n",
      "Page 26: 4 of 4 incidents added to DB. Total incidents: 385\n",
      "Page 27: 9 of 9 incidents added to DB. Total incidents: 394\n",
      "Page 28: 5 of 5 incidents added to DB. Total incidents: 399\n",
      "Page 29: 8 of 8 incidents added to DB. Total incidents: 407\n",
      "Page 30: 9 of 9 incidents added to DB. Total incidents: 416\n",
      "Page 31: 9 of 9 incidents added to DB. Total incidents: 425\n",
      "Page 32: 8 of 8 incidents added to DB. Total incidents: 433\n",
      "Page 33: 8 of 8 incidents added to DB. Total incidents: 441\n",
      "Page 34: 8 of 8 incidents added to DB. Total incidents: 449\n",
      "Page 35: 7 of 7 incidents added to DB. Total incidents: 456\n",
      "Page 36: 9 of 9 incidents added to DB. Total incidents: 465\n",
      "Page 37: 9 of 9 incidents added to DB. Total incidents: 474\n",
      "Page 38: 9 of 9 incidents added to DB. Total incidents: 483\n",
      "Page 39: 9 of 9 incidents added to DB. Total incidents: 492\n",
      "Page 40: 8 of 8 incidents added to DB. Total incidents: 500\n",
      "Page 41: 8 of 8 incidents added to DB. Total incidents: 508\n",
      "Page 42: 10 of 10 incidents added to DB. Total incidents: 518\n",
      "Page 43: 9 of 9 incidents added to DB. Total incidents: 527\n",
      "Page 44: 9 of 9 incidents added to DB. Total incidents: 536\n",
      "Page 45: 9 of 9 incidents added to DB. Total incidents: 545\n",
      "Page 46: 9 of 9 incidents added to DB. Total incidents: 554\n",
      "Page 47: 10 of 10 incidents added to DB. Total incidents: 564\n",
      "Page 48: 9 of 9 incidents added to DB. Total incidents: 573\n",
      "Page 49: 8 of 8 incidents added to DB. Total incidents: 581\n",
      "Page 50: 8 of 8 incidents added to DB. Total incidents: 589\n",
      "Page 51: 10 of 10 incidents added to DB. Total incidents: 599\n",
      "Page 52: 9 of 9 incidents added to DB. Total incidents: 608\n",
      "Page 53: 8 of 8 incidents added to DB. Total incidents: 616\n",
      "Page 54: 9 of 9 incidents added to DB. Total incidents: 625\n",
      "Page 55: 6 of 6 incidents added to DB. Total incidents: 631\n",
      "Page 56: 8 of 8 incidents added to DB. Total incidents: 639\n",
      "Page 57: 8 of 8 incidents added to DB. Total incidents: 647\n",
      "Page 58: 8 of 8 incidents added to DB. Total incidents: 655\n",
      "Page 59: 9 of 9 incidents added to DB. Total incidents: 664\n",
      "Page 60: 9 of 9 incidents added to DB. Total incidents: 673\n",
      "Page 61: 7 of 7 incidents added to DB. Total incidents: 680\n",
      "Page 62: 9 of 9 incidents added to DB. Total incidents: 689\n",
      "Page 63: 8 of 8 incidents added to DB. Total incidents: 697\n",
      "Page 64: 9 of 9 incidents added to DB. Total incidents: 706\n",
      "Page 65: 7 of 7 incidents added to DB. Total incidents: 713\n",
      "Page 66: 7 of 7 incidents added to DB. Total incidents: 720\n",
      "Page 67: 8 of 8 incidents added to DB. Total incidents: 728\n",
      "Page 68: 7 of 7 incidents added to DB. Total incidents: 735\n",
      "Page 69: 7 of 7 incidents added to DB. Total incidents: 742\n",
      "Page 70: 6 of 6 incidents added to DB. Total incidents: 748\n",
      "Page 71: 8 of 8 incidents added to DB. Total incidents: 756\n",
      "Page 72: 9 of 9 incidents added to DB. Total incidents: 765\n",
      "Page 73: 10 of 10 incidents added to DB. Total incidents: 775\n",
      "Page 74: 9 of 9 incidents added to DB. Total incidents: 784\n",
      "Page 75: 9 of 9 incidents added to DB. Total incidents: 793\n",
      "Page 76: 6 of 6 incidents added to DB. Total incidents: 799\n",
      "Page 77: 9 of 9 incidents added to DB. Total incidents: 808\n",
      "Page 78: 9 of 9 incidents added to DB. Total incidents: 817\n",
      "Page 79: 10 of 10 incidents added to DB. Total incidents: 827\n",
      "Page 80: 9 of 9 incidents added to DB. Total incidents: 836\n",
      "Page 81: 9 of 9 incidents added to DB. Total incidents: 845\n",
      "Page 82: 9 of 9 incidents added to DB. Total incidents: 854\n",
      "Page 83: 9 of 9 incidents added to DB. Total incidents: 863\n",
      "Page 84: 9 of 9 incidents added to DB. Total incidents: 872\n",
      "Page 85: 7 of 7 incidents added to DB. Total incidents: 879\n",
      "Page 86: 8 of 8 incidents added to DB. Total incidents: 887\n",
      "Page 87: 7 of 7 incidents added to DB. Total incidents: 894\n",
      "Page 88: 8 of 8 incidents added to DB. Total incidents: 902\n",
      "Page 89: 5 of 5 incidents added to DB. Total incidents: 907\n",
      "Page 90: 9 of 9 incidents added to DB. Total incidents: 916\n",
      "Page 91: 8 of 8 incidents added to DB. Total incidents: 924\n",
      "Page 92: 8 of 8 incidents added to DB. Total incidents: 932\n",
      "Page 93: 9 of 9 incidents added to DB. Total incidents: 941\n",
      "Page 94: 10 of 10 incidents added to DB. Total incidents: 951\n",
      "Page 95: 7 of 7 incidents added to DB. Total incidents: 958\n",
      "Page 96: 10 of 10 incidents added to DB. Total incidents: 968\n",
      "Page 97: 8 of 8 incidents added to DB. Total incidents: 976\n",
      "Page 98: 9 of 9 incidents added to DB. Total incidents: 985\n",
      "Page 99: 8 of 8 incidents added to DB. Total incidents: 993\n",
      "Page 100: 9 of 9 incidents added to DB. Total incidents: 1002\n",
      "Page 101: 7 of 7 incidents added to DB. Total incidents: 1009\n",
      "Page 102: 10 of 10 incidents added to DB. Total incidents: 1019\n",
      "Page 103: 7 of 7 incidents added to DB. Total incidents: 1026\n",
      "Page 104: 9 of 9 incidents added to DB. Total incidents: 1035\n",
      "Page 105: 10 of 10 incidents added to DB. Total incidents: 1045\n",
      "Page 106: 9 of 9 incidents added to DB. Total incidents: 1054\n",
      "Page 107: 9 of 9 incidents added to DB. Total incidents: 1063\n",
      "Page 108: 6 of 6 incidents added to DB. Total incidents: 1069\n",
      "Page 109: 6 of 6 incidents added to DB. Total incidents: 1075\n",
      "Page 110: 10 of 10 incidents added to DB. Total incidents: 1085\n",
      "Page 111: 10 of 10 incidents added to DB. Total incidents: 1095\n",
      "Page 112: 10 of 10 incidents added to DB. Total incidents: 1105\n",
      "Page 113: 9 of 9 incidents added to DB. Total incidents: 1114\n",
      "Page 114: 8 of 8 incidents added to DB. Total incidents: 1122\n",
      "Page 115: 9 of 9 incidents added to DB. Total incidents: 1131\n",
      "Page 116: 9 of 9 incidents added to DB. Total incidents: 1140\n",
      "Page 117: 9 of 9 incidents added to DB. Total incidents: 1149\n",
      "Page 118: 7 of 7 incidents added to DB. Total incidents: 1156\n",
      "Page 119: 10 of 10 incidents added to DB. Total incidents: 1166\n",
      "Page 120: 9 of 9 incidents added to DB. Total incidents: 1175\n",
      "Page 121: 7 of 7 incidents added to DB. Total incidents: 1182\n",
      "Page 122: 7 of 7 incidents added to DB. Total incidents: 1189\n",
      "Page 123: 6 of 6 incidents added to DB. Total incidents: 1195\n",
      "Page 124: 8 of 8 incidents added to DB. Total incidents: 1203\n",
      "Page 125: 10 of 10 incidents added to DB. Total incidents: 1213\n",
      "Page 126: 9 of 9 incidents added to DB. Total incidents: 1222\n",
      "Page 127: 8 of 8 incidents added to DB. Total incidents: 1230\n",
      "Page 128: 10 of 10 incidents added to DB. Total incidents: 1240\n",
      "Page 129: 8 of 8 incidents added to DB. Total incidents: 1248\n",
      "Page 130: 6 of 6 incidents added to DB. Total incidents: 1254\n",
      "Page 131: 9 of 9 incidents added to DB. Total incidents: 1263\n",
      "Page 132: 9 of 9 incidents added to DB. Total incidents: 1272\n",
      "Page 133: 7 of 7 incidents added to DB. Total incidents: 1279\n",
      "Page 134: 10 of 10 incidents added to DB. Total incidents: 1289\n",
      "Page 135: 9 of 9 incidents added to DB. Total incidents: 1298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 136: 10 of 10 incidents added to DB. Total incidents: 1308\n",
      "Page 137: 10 of 10 incidents added to DB. Total incidents: 1318\n",
      "Page 138: 10 of 10 incidents added to DB. Total incidents: 1328\n",
      "Page 139: 9 of 9 incidents added to DB. Total incidents: 1337\n",
      "Page 140: 10 of 10 incidents added to DB. Total incidents: 1347\n",
      "Page 141: 10 of 10 incidents added to DB. Total incidents: 1357\n",
      "Page 142: 10 of 10 incidents added to DB. Total incidents: 1367\n",
      "Page 143: 10 of 10 incidents added to DB. Total incidents: 1377\n",
      "Page 144: 10 of 10 incidents added to DB. Total incidents: 1387\n",
      "Page 145: 10 of 10 incidents added to DB. Total incidents: 1397\n",
      "Page 146: 8 of 8 incidents added to DB. Total incidents: 1405\n",
      "Page 147: 8 of 8 incidents added to DB. Total incidents: 1413\n",
      "Page 148: 9 of 9 incidents added to DB. Total incidents: 1422\n",
      "Page 149: 10 of 10 incidents added to DB. Total incidents: 1432\n",
      "Page 150: 10 of 10 incidents added to DB. Total incidents: 1442\n",
      "Page 151: 9 of 9 incidents added to DB. Total incidents: 1451\n",
      "Page 152: 7 of 7 incidents added to DB. Total incidents: 1458\n",
      "Page 153: 8 of 8 incidents added to DB. Total incidents: 1466\n",
      "Page 154: 10 of 10 incidents added to DB. Total incidents: 1476\n",
      "Page 155: 8 of 8 incidents added to DB. Total incidents: 1484\n",
      "Page 156: 10 of 10 incidents added to DB. Total incidents: 1494\n",
      "Page 157: 10 of 10 incidents added to DB. Total incidents: 1504\n",
      "Page 158: 10 of 10 incidents added to DB. Total incidents: 1514\n",
      "Page 159: 10 of 10 incidents added to DB. Total incidents: 1524\n",
      "Page 160: 10 of 10 incidents added to DB. Total incidents: 1534\n",
      "Page 161: 9 of 9 incidents added to DB. Total incidents: 1543\n",
      "Page 162: 9 of 9 incidents added to DB. Total incidents: 1552\n",
      "Page 163: 10 of 10 incidents added to DB. Total incidents: 1562\n",
      "Page 164: 10 of 10 incidents added to DB. Total incidents: 1572\n",
      "Page 165: 9 of 9 incidents added to DB. Total incidents: 1581\n",
      "Page 166: 8 of 8 incidents added to DB. Total incidents: 1589\n",
      "Page 167: 10 of 10 incidents added to DB. Total incidents: 1599\n",
      "Page 168: 6 of 6 incidents added to DB. Total incidents: 1605\n",
      "Page 169: 8 of 8 incidents added to DB. Total incidents: 1613\n",
      "Page 170: 7 of 7 incidents added to DB. Total incidents: 1620\n",
      "Page 171: 10 of 10 incidents added to DB. Total incidents: 1630\n",
      "Page 172: 10 of 10 incidents added to DB. Total incidents: 1640\n",
      "Page 173: 7 of 7 incidents added to DB. Total incidents: 1647\n",
      "Page 174: 9 of 9 incidents added to DB. Total incidents: 1656\n",
      "Page 175: 10 of 10 incidents added to DB. Total incidents: 1666\n",
      "Page 176: 6 of 6 incidents added to DB. Total incidents: 1672\n",
      "Page 177: 7 of 7 incidents added to DB. Total incidents: 1679\n",
      "Page 178: 5 of 5 incidents added to DB. Total incidents: 1684\n",
      "Page 179: 7 of 7 incidents added to DB. Total incidents: 1691\n",
      "Page 180: 8 of 8 incidents added to DB. Total incidents: 1699\n",
      "Page 181: 9 of 9 incidents added to DB. Total incidents: 1708\n",
      "Page 182: 10 of 10 incidents added to DB. Total incidents: 1718\n",
      "Page 183: 8 of 8 incidents added to DB. Total incidents: 1726\n",
      "Page 184: 10 of 10 incidents added to DB. Total incidents: 1736\n",
      "Page 185: 8 of 8 incidents added to DB. Total incidents: 1744\n",
      "Page 186: 10 of 10 incidents added to DB. Total incidents: 1754\n",
      "Page 187: 7 of 7 incidents added to DB. Total incidents: 1761\n",
      "Page 188: 7 of 7 incidents added to DB. Total incidents: 1768\n",
      "Page 189: 4 of 4 incidents added to DB. Total incidents: 1772\n",
      "Page 190: 8 of 8 incidents added to DB. Total incidents: 1780\n",
      "Page 191: 8 of 8 incidents added to DB. Total incidents: 1788\n",
      "Page 192: 10 of 10 incidents added to DB. Total incidents: 1798\n",
      "Page 193: 10 of 10 incidents added to DB. Total incidents: 1808\n",
      "Page 194: 8 of 8 incidents added to DB. Total incidents: 1816\n",
      "Page 195: 9 of 9 incidents added to DB. Total incidents: 1825\n",
      "Page 196: 9 of 9 incidents added to DB. Total incidents: 1834\n",
      "Page 197: 10 of 10 incidents added to DB. Total incidents: 1844\n",
      "Page 198: 8 of 8 incidents added to DB. Total incidents: 1852\n",
      "Page 199: 8 of 8 incidents added to DB. Total incidents: 1860\n",
      "Page 200: 10 of 10 incidents added to DB. Total incidents: 1870\n",
      "Page 201: 10 of 10 incidents added to DB. Total incidents: 1880\n",
      "Page 202: 10 of 10 incidents added to DB. Total incidents: 1890\n",
      "Page 203: 8 of 8 incidents added to DB. Total incidents: 1898\n",
      "Page 204: 10 of 10 incidents added to DB. Total incidents: 1908\n",
      "Page 205: 7 of 7 incidents added to DB. Total incidents: 1915\n",
      "Page 206: 7 of 7 incidents added to DB. Total incidents: 1922\n",
      "Page 207: 9 of 9 incidents added to DB. Total incidents: 1931\n",
      "Page 208: 10 of 10 incidents added to DB. Total incidents: 1941\n",
      "Page 209: 9 of 9 incidents added to DB. Total incidents: 1950\n",
      "Page 210: 9 of 9 incidents added to DB. Total incidents: 1959\n",
      "Page 211: 10 of 10 incidents added to DB. Total incidents: 1969\n",
      "Page 212: 8 of 8 incidents added to DB. Total incidents: 1977\n",
      "Page 213: 10 of 10 incidents added to DB. Total incidents: 1987\n",
      "Page 214: 9 of 9 incidents added to DB. Total incidents: 1996\n",
      "Page 215: 8 of 8 incidents added to DB. Total incidents: 2004\n",
      "Page 216: 10 of 10 incidents added to DB. Total incidents: 2014\n",
      "Page 217: 9 of 9 incidents added to DB. Total incidents: 2023\n",
      "Page 218: 8 of 8 incidents added to DB. Total incidents: 2031\n",
      "Page 219: 9 of 9 incidents added to DB. Total incidents: 2040\n",
      "Page 220: 8 of 8 incidents added to DB. Total incidents: 2048\n",
      "Page 221: 10 of 10 incidents added to DB. Total incidents: 2058\n",
      "Page 222: 8 of 8 incidents added to DB. Total incidents: 2066\n",
      "Page 223: 8 of 8 incidents added to DB. Total incidents: 2074\n",
      "Page 224: 9 of 9 incidents added to DB. Total incidents: 2083\n",
      "Page 225: 8 of 8 incidents added to DB. Total incidents: 2091\n",
      "Page 226: 7 of 7 incidents added to DB. Total incidents: 2098\n",
      "Page 227: 8 of 8 incidents added to DB. Total incidents: 2106\n",
      "Page 228: 10 of 10 incidents added to DB. Total incidents: 2116\n",
      "Page 229: 10 of 10 incidents added to DB. Total incidents: 2126\n",
      "Page 230: 10 of 10 incidents added to DB. Total incidents: 2136\n",
      "Page 231: 9 of 9 incidents added to DB. Total incidents: 2145\n",
      "Page 232: 8 of 8 incidents added to DB. Total incidents: 2153\n",
      "Page 233: 8 of 8 incidents added to DB. Total incidents: 2161\n",
      "Page 234: 7 of 7 incidents added to DB. Total incidents: 2168\n",
      "Page 235: 7 of 7 incidents added to DB. Total incidents: 2175\n",
      "Page 236: 9 of 9 incidents added to DB. Total incidents: 2184\n",
      "Page 237: 7 of 7 incidents added to DB. Total incidents: 2191\n",
      "Page 238: 9 of 9 incidents added to DB. Total incidents: 2200\n",
      "Page 239: 8 of 8 incidents added to DB. Total incidents: 2208\n",
      "Page 240: 8 of 8 incidents added to DB. Total incidents: 2216\n",
      "Page 241: 8 of 8 incidents added to DB. Total incidents: 2224\n",
      "Page 242: 7 of 7 incidents added to DB. Total incidents: 2231\n",
      "Page 243: 9 of 9 incidents added to DB. Total incidents: 2240\n",
      "Page 244: 8 of 8 incidents added to DB. Total incidents: 2248\n",
      "Page 245: 9 of 9 incidents added to DB. Total incidents: 2257\n",
      "Page 246: 10 of 10 incidents added to DB. Total incidents: 2267\n",
      "Page 247: 9 of 9 incidents added to DB. Total incidents: 2276\n",
      "Page 248: 9 of 9 incidents added to DB. Total incidents: 2285\n",
      "Page 249: 9 of 9 incidents added to DB. Total incidents: 2294\n",
      "Page 250: 10 of 10 incidents added to DB. Total incidents: 2304\n",
      "Page 251: 10 of 10 incidents added to DB. Total incidents: 2314\n",
      "Page 252: 8 of 8 incidents added to DB. Total incidents: 2322\n",
      "Page 253: 9 of 9 incidents added to DB. Total incidents: 2331\n",
      "Page 254: 8 of 8 incidents added to DB. Total incidents: 2339\n",
      "Page 255: 6 of 6 incidents added to DB. Total incidents: 2345\n",
      "Page 256: 8 of 8 incidents added to DB. Total incidents: 2353\n",
      "Page 257: 10 of 10 incidents added to DB. Total incidents: 2363\n",
      "Page 258: 10 of 10 incidents added to DB. Total incidents: 2373\n",
      "Page 259: 7 of 7 incidents added to DB. Total incidents: 2380\n",
      "Page 260: 8 of 8 incidents added to DB. Total incidents: 2388\n",
      "Page 261: 7 of 7 incidents added to DB. Total incidents: 2395\n",
      "Page 262: 9 of 9 incidents added to DB. Total incidents: 2404\n",
      "Page 263: 10 of 10 incidents added to DB. Total incidents: 2414\n",
      "Page 264: 8 of 8 incidents added to DB. Total incidents: 2422\n",
      "Page 265: 9 of 9 incidents added to DB. Total incidents: 2431\n",
      "Page 266: 9 of 9 incidents added to DB. Total incidents: 2440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 267: 7 of 7 incidents added to DB. Total incidents: 2447\n",
      "Page 268: 9 of 9 incidents added to DB. Total incidents: 2456\n",
      "Page 269: 8 of 8 incidents added to DB. Total incidents: 2464\n",
      "Page 270: 9 of 9 incidents added to DB. Total incidents: 2473\n",
      "Page 271: 10 of 10 incidents added to DB. Total incidents: 2483\n",
      "Page 272: 10 of 10 incidents added to DB. Total incidents: 2493\n",
      "Page 273: 9 of 9 incidents added to DB. Total incidents: 2502\n",
      "Page 274: 8 of 8 incidents added to DB. Total incidents: 2510\n",
      "Page 275: 8 of 8 incidents added to DB. Total incidents: 2518\n",
      "Page 276: 9 of 9 incidents added to DB. Total incidents: 2527\n",
      "Page 277: 9 of 9 incidents added to DB. Total incidents: 2536\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-ada94e4ab7a6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpage_target\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;31m# Get a page full of incidents from the USA\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mi_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparse_incident_page\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbrowser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhtml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[0mn_pages\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-5931b7250301>\u001b[0m in \u001b[0;36mparse_incident_page\u001b[1;34m(a_html)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[1;31m# Parse this incident\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m             \u001b[0mincident_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparse_one_incident\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m             \u001b[1;31m#pprint(incident_info)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-9b9c659bd767>\u001b[0m in \u001b[0;36mparse_one_incident\u001b[1;34m(a_bsobj)\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;31m# Go to the detail page to get the one piece of info we\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[1;31m# need that's not on the main page - the address!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m     \u001b[0mincident_address_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_incident_detail\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mincident_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[1;31m# Place all this good info into a dictionary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-462b39200261>\u001b[0m in \u001b[0;36mget_incident_detail\u001b[1;34m(a_url)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[1;31m# City\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m             \u001b[0mincident_address_city\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mai_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mai_size\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m             \u001b[1;31m# Process up to 3 \"street\" type entries\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# URL of page to be scraped\n",
    "# url_iwp = 'https://iwaspoisoned.com'\n",
    "url_iwp = 'https://iwaspoisoned.com/?page=25#'\n",
    "\n",
    "# Visit the IWP page\n",
    "browser.visit( url_iwp )\n",
    "\n",
    "# Extract incidents from multiple pages\n",
    "page_target = 20000\n",
    "\n",
    "# How long to wait between pages to avoid triggering issues on website\n",
    "page_wait = 2\n",
    "\n",
    "# Count the number of pages visited\n",
    "n_pages = 0\n",
    "\n",
    "# Loop until no more pages or until page target is reached\n",
    "full_incident_list = []\n",
    "for j in range(page_target):\n",
    "    # Get a page full of incidents from the USA\n",
    "    i_list = parse_incident_page(browser.html)\n",
    "    n_pages += 1\n",
    "    \n",
    "    # Add this list of incidents to a running list\n",
    "    # full_incident_list.extend(i_list)\n",
    "    \n",
    "    # Add this list of incidents to the Mongo database\n",
    "    # update_results = db.iwp.update_many({}, i_list, upsert=True)\n",
    "    insert_results = db.iwp.insert_many(i_list)\n",
    "        \n",
    "    # Print a progress marker\n",
    "    try:\n",
    "        print(f\"Page {n_pages}: {len(insert_results.inserted_ids)} of {len(i_list)} incidents added to DB. Total incidents: {db.iwp.count_documents({})}\")\n",
    "\n",
    "    except TypeError:\n",
    "        print(f\">> Page {n_pages}: TypeError\")\n",
    "    \n",
    "    # Check to see if a hyperlink with attribute 'rel' = 'next' is present\n",
    "    soup_thispage = BeautifulSoup(browser.html, 'lxml')\n",
    "    next_tag = soup_thispage.find('a', {'rel' : 'next'})\n",
    "        \n",
    "    if next_tag:\n",
    "        # Ok, there is a next page - get the hyperlink\n",
    "        try:\n",
    "            next_page_url = next_tag['href']\n",
    "    \n",
    "            # Wait for a specified number of seconds\n",
    "            time.sleep(page_wait)\n",
    "\n",
    "            # Click it!\n",
    "            browser.click_link_by_href(next_page_url)\n",
    "\n",
    "            #DEBUG ****************************************\n",
    "            # if n_pages > 3:\n",
    "            #    break\n",
    "            \n",
    "        # If KeyError occurs, then this tag has no html link for some reason\n",
    "        except KeyError:\n",
    "            break\n",
    "            \n",
    "    else:\n",
    "        # No more pages - break out of this loop\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display items in MongoDB collection\n",
    "#all_incidents = db.iwp.find()\n",
    "\n",
    "#j=0\n",
    "#for i in all_incidents:\n",
    "#    print(f\"{j}: {i['incident_title']}\")\n",
    "#    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
